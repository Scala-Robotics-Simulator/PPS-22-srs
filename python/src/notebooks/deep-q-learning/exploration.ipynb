{
 "cells": [
  {
   "cell_type": "code",
   "id": "327b422d-9465-4a80-9167-542769292775",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:57:25.652552Z",
     "start_time": "2026-01-16T14:57:25.643013Z"
    }
   },
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "b218428e-774a-4027-aea5-4a35fe61ebb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:57:26.380132Z",
     "start_time": "2026-01-16T14:57:26.368581Z"
    }
   },
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:57:27.148450Z",
     "start_time": "2026-01-16T14:57:26.405038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from environment.deepqlearning.exploration_env import ExplorationEnv\n",
    "from utils.reader import get_yaml_path, read_file"
   ],
   "id": "89d6ebe7ec357191",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:57:27.258973Z",
     "start_time": "2026-01-16T14:57:27.221054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "server_address = \"localhost:50051\"\n",
    "client_name = \"RLClient\"\n",
    "env = ExplorationEnv(server_address, client_name)\n",
    "env.connect_to_client()"
   ],
   "id": "bb1c3478b4af584e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-16 15:57:27,255 — INFO — ✓ Connected to localhost:50051\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "e10681cc-166e-4125-a125-06bf5a9a94ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:57:27.387898Z",
     "start_time": "2026-01-16T14:57:27.371798Z"
    }
   },
   "source": [
    "config_path = get_yaml_path(\"src\", \"scripts\", \"resources\", \"environments\", \"exploration\", \"dq-learning\", \"10x10\", \"environment_0000.yml\")\n",
    "\n",
    "config = read_file(config_path)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "80a0e14e-a9bb-444b-b697-f6437de0487f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:57:27.502172Z",
     "start_time": "2026-01-16T14:57:27.475906Z"
    }
   },
   "source": [
    "env.init(config)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, '')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "13294261-98f7-496e-b835-b76819e2c4c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:57:47.144467Z",
     "start_time": "2026-01-16T14:57:27.581361Z"
    }
   },
   "source": [
    "from agent.scala_dqagent import DQAgent\n",
    "from training.dqnetwork import DQNetwork"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "3a2d31b8-f664-416b-b278-7f66ec8d9f28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:57:47.193443Z",
     "start_time": "2026-01-16T14:57:47.181219Z"
    }
   },
   "source": "neuron_count_per_hidden_layer = [128, 64, 32]",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "bdbdc14a-eb5d-4a09-a148-22beb9f06309",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:57:59.558235Z",
     "start_time": "2026-01-16T14:57:47.246484Z"
    }
   },
   "source": [
    "agent1 = DQAgent(\n",
    "    env,\n",
    "    agent_id=\"00000000-0000-0000-0000-000000000001\",\n",
    "    action_model=DQNetwork(\n",
    "        env.observation_space.shape,\n",
    "        neuron_count_per_hidden_layer,\n",
    "        env.action_space.n,\n",
    "        summary=False,\n",
    "    ),\n",
    "    target_model=DQNetwork(\n",
    "        env.observation_space.shape,\n",
    "        neuron_count_per_hidden_layer,\n",
    "        env.action_space.n,\n",
    "        summary=False,\n",
    "    ),\n",
    ")\n",
    "agents = [agent1]"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:58:00.035233Z",
     "start_time": "2026-01-16T14:57:59.626136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = get_yaml_path(\"src\", \"scripts\", \"resources\", \"checkpoints\", \"exploration\", \"dq-learning\", \"checkpoints_ep3081\")\n",
    "for agent in agents:\n",
    "    agent.load(path)"
   ],
   "id": "c49a5913995ff397",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Desktop\\UNIBO\\LaureaMagistrale\\1_anno\\Paradigmi di Programmazione e Sviluppo (PPS)\\Esame\\PPS-22-srs\\python\\.venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 18 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:58:00.386570Z",
     "start_time": "2026-01-16T14:58:00.066412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "from training.multi_agent_dqlearning import DQLearning\n",
    "\n",
    "trainer = DQLearning(\n",
    "    env,\n",
    "    agents,\n",
    "    configs = [],\n",
    ")"
   ],
   "id": "a20c3e8b5b11fd59",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:58:07.027447Z",
     "start_time": "2026-01-16T14:58:00.438533Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.play_with_pygame(fps=60)",
   "id": "501df77f23030b5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-16 15:58:06,843 — INFO — Episode 1/1 - Reward: 87.97255025289832\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:58:07.152743Z",
     "start_time": "2026-01-16T14:58:07.142506Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "447bef0c436485c1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
