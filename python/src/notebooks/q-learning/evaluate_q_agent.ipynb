{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70de0b88-d204-4424-8d02-8e54e364f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2e4519f-abe6-49fe-8de5-3f00b47fda80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8721608c-35e5-474c-98bb-ab23ed67068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# environments\n",
    "\n",
    "from environment.qlearning.obstacle_avoidance_env import ObstacleAvoidanceEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fccf5d58-dc14-4322-8658-8afca7e76a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.reader import get_yaml_path, read_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf51e110-5be2-420c-b340-ef719ee93826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.qagent import QAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df0696f9-a093-46e2-8380-36524a016d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 17:28:03.616550: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-28 17:28:03.653794: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-28 17:28:06.617043: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from evaluation.agent_evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4b3efa7-2bc2-4fab-bc98-aefead32a01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plotting import plot_all_q_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60a4739e-10ff-4589-b7d2-3117451a76ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-28 17:28:07,491 — INFO — ✓ Connected to localhost:50051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "server_address = \"localhost:50051\" # adjust the port as needed\n",
    "client_name = \"RLClient\"\n",
    "env = ObstacleAvoidanceEnv(server_address, client_name) # adjust the env as needed\n",
    "env.connect_to_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e8e5ef6-90cb-42f7-8f62-23eb147abc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = {\n",
    "    f\"00000000-0000-0000-0000-{(i+1):012d}\": QAgent(env)\n",
    "    for i in range(30)\n",
    "}\n",
    "# agent = QAgent(env)\n",
    "# agent_id = \"00000000-0000-0000-0000-000000000001\"\n",
    "# agents = { agent_id: agent }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b1d3571-54dd-463d-b490-ae3323b715a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "configs_path = get_yaml_path(\"src\", \"scripts\", \"resources\", \"generated\", \"evaluation\", \"q-learning\", \"obstacle-avoidance\", \"multi-agent\")\n",
    "yml_files = sorted(configs_path.glob(\"*.yml\"), key=lambda p: p.name)\n",
    "configs = [read_file(f) for f in yml_files]\n",
    "print(len(configs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3be3a9e6-100c-48d1-a694-d3e77ba51d10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-28 17:28:07,510 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,510 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,510 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,511 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,512 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,512 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,512 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,512 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,513 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,513 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,513 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,513 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,514 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,514 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,515 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,515 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,515 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,516 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,516 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,516 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,517 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,517 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,517 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,518 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,518 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,519 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,519 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,519 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,520 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,520 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,520 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,520 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,521 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,521 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,522 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,522 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,523 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,523 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,523 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,524 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,524 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,525 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,525 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,525 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,526 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,526 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,526 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,526 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,527 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,527 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,527 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,527 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,528 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,528 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,529 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,529 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,529 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,530 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,530 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,530 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,530 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,531 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,531 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,531 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,532 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,532 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,532 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,532 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,533 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,533 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,533 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,533 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,534 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,534 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,534 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,535 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,536 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,536 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,537 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,537 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,538 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,538 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,538 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,538 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,539 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,539 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,540 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,540 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,540 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,541 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,541 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,541 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,542 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,542 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,542 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,542 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,543 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,543 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,544 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,544 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,545 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,545 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,545 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,546 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,547 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,547 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,547 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,547 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,548 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,548 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,548 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,549 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,549 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,550 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,550 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,550 — INFO —   Total episodes trained: 884\n",
      "2025-11-28 17:28:07,551 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/scripts/resources/generated/checkpoints/obstacle-avoidance/q-learning/v1/oa_ep884.npz\n",
      "2025-11-28 17:28:07,551 — INFO —   Q-table shape: (64, 5)\n",
      "2025-11-28 17:28:07,551 — INFO —   Current epsilon: 0.1318\n",
      "2025-11-28 17:28:07,551 — INFO —   Total episodes trained: 884\n"
     ]
    }
   ],
   "source": [
    "agent_path = get_yaml_path(\"src\", \"scripts\", \"resources\", \"generated\", \"checkpoints\", \"obstacle-avoidance\", \"q-learning\", \"v1\", \"oa_ep884\")\n",
    "for agent in agents.values():\n",
    "    agent.load(agent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58c71847-6d44-4fe4-80da-59bbacc569e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "did_succeed=lambda reward, termination, truncation: True if truncation and reward > -500 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "133d8e05-697b-4e2e-b654-6a56b6800ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:  30%|█████████████████████████████████████████████████████                                                                                                                            | 3/10 [00:11<00:26,  3.74s/configuration run]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n",
      "[3, 3, 3]\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:  50%|████████████████████████████████████████████████████████████████████████████████████████▌                                                                                        | 5/10 [00:21<00:21,  4.27s/configuration run]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magents\u001b[49m\u001b[43m=\u001b[49m\u001b[43magents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdid_succeed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdid_succeed\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# TODO: 5000 steps\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/notebooks/q-learning/../../evaluation/agent_evaluation.py:59\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(env, agents, configs, max_steps, did_succeed, window_size)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done \u001b[38;5;129;01mand\u001b[39;00m step < max_steps:\n\u001b[32m     53\u001b[39m     actions = {\n\u001b[32m     54\u001b[39m         k: agents[k].choose_action(v, epsilon_greedy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     55\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obs.items()\n\u001b[32m     56\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m prev_dones[k]\n\u001b[32m     57\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     next_obs, rewards, terminateds, truncateds, _ = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m rewards[\u001b[33m\"\u001b[39m\u001b[33m00000000-0000-0000-0000-000000000005\u001b[39m\u001b[33m\"\u001b[39m] < -\u001b[32m900\u001b[39m:\n\u001b[32m     61\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     62\u001b[39m             decode_observation(next_obs[\u001b[33m\"\u001b[39m\u001b[33m00000000-0000-0000-0000-000000000005\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     63\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/notebooks/q-learning/../../environment/abstract_env.py:107\u001b[39m, in \u001b[36mAbstractEnv.step\u001b[39m\u001b[34m(self, actions)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Take a step in the environment with the given actions\u001b[39;00m\n\u001b[32m     94\u001b[39m \n\u001b[32m     95\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m \u001b[33;03m    A tuple containing observations, rewards, terminateds, truncateds, and infos.\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    105\u001b[39m actions = \u001b[38;5;28mself\u001b[39m._decode_actions(actions)\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m observations, rewards, terminateds, truncateds, infos = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_async\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    111\u001b[39m     \u001b[38;5;28mself\u001b[39m._encode_observations(observations),\n\u001b[32m    112\u001b[39m     rewards,\n\u001b[32m   (...)\u001b[39m\u001b[32m    115\u001b[39m     infos,\n\u001b[32m    116\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uni-lab/PPS/2024/SRS/PPS-22-srs/docs/obstacle-avoidance/python/src/notebooks/q-learning/../../environment/abstract_env.py:42\u001b[39m, in \u001b[36mAbstractEnv._run_async\u001b[39m\u001b[34m(self, coro)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, coro):\n\u001b[32m     41\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Helper method to run async coroutines synchronously\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoro\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/pwrhqv9fy9lbybjz9c1w283z234lzksr-python3-3.13.8-env/lib/python3.13/site-packages/nest_asyncio.py:92\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     90\u001b[39m     f._log_destroy_pending = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping:\n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/pwrhqv9fy9lbybjz9c1w283z234lzksr-python3-3.13.8-env/lib/python3.13/site-packages/nest_asyncio.py:115\u001b[39m, in \u001b[36m_patch_loop.<locals>._run_once\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    108\u001b[39m     heappop(scheduled)\n\u001b[32m    110\u001b[39m timeout = (\n\u001b[32m    111\u001b[39m     \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[32m    113\u001b[39m         scheduled[\u001b[32m0\u001b[39m]._when - \u001b[38;5;28mself\u001b[39m.time(), \u001b[32m0\u001b[39m), \u001b[32m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m._process_events(event_list)\n\u001b[32m    118\u001b[39m end_time = \u001b[38;5;28mself\u001b[39m.time() + \u001b[38;5;28mself\u001b[39m._clock_resolution\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/cfapjd2rvqrpry4grb0kljnp8bvnvfxz-python3-3.13.8/lib/python3.13/selectors.py:452\u001b[39m, in \u001b[36mEpollSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    450\u001b[39m ready = []\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "results = evaluate(env=env, agents=agents, configs=configs, max_steps=500, did_succeed=did_succeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca39338d-11f3-44d8-afe1-09a5834512ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['moving_avg_reward'][\"00000000-0000-0000-0000-000000000005\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70ade13-2795-467d-808c-793073a7ddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_q_agent(results, agents=list(agents.keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
