{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show training results from a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all envs\n",
    "\n",
    "from environment.qlearning.obstacle_avoidance_env import ObstacleAvoidanceEnv\n",
    "from environment.qlearning.phototaxis_env import PhototaxisEnv\n",
    "from utils.reader import get_yaml_path, read_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.qagent import QAgent\n",
    "from training.qlearning import QLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:488: RuntimeWarning: Your system is avx2 capable but pygame was not built with support for it. The performance of some of your blits could be adversely affected. Consider enabling compile time detection with environment variables like PYGAME_DETECT_AVX2=1 if you are compiling without cross compilation.\n",
      "/nix/store/xfj6pw68yzxq174as0lggbfpqkgxn6z5-python3-3.13.8-env/lib/python3.13/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:05:07,420 — INFO — ✓ Connected to localhost:50060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "server_address = \"localhost:50060\" # adjust the port as needed\n",
    "client_name = \"RLClient\"\n",
    "env = ObstacleAvoidanceEnv(server_address, client_name) # adjust the env as needed\n",
    "env.connect_to_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configuration - Original Complex Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = get_yaml_path(\"resources\", \"configurations\", \"obstacle-avoidance.yml\") # adjust the configuration as needed\n",
    "config = read_file(config_path)\n",
    "\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:05:07,440 — INFO — ✓ Initialization successful\n"
     ]
    }
   ],
   "source": [
    "env.init(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = QAgent(env)\n",
    "agentId = \"00000000-0000-0000-0000-000000000001\"\n",
    "agents = { agentId: agent }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episodes(\n",
    "    episode_count, \n",
    "    episode_max_steps, \n",
    "    render=False, \n",
    "    fps=60,\n",
    "    checkpoint_interval=None,\n",
    "    checkpoint_path=\"checkpoints/phototaxis_agent\",\n",
    "    load_checkpoint=None,\n",
    "    start_episode=0\n",
    "):\n",
    "    import os\n",
    "    \n",
    "    # Load existing agent if specified\n",
    "    if load_checkpoint:\n",
    "        for agent_id, agent_obj in agents.items():\n",
    "            agent_obj.load(load_checkpoint)\n",
    "            print(f\"Loaded agent from {load_checkpoint}\")\n",
    "    \n",
    "    # Create checkpoint directory if needed\n",
    "    if checkpoint_interval:\n",
    "        os.makedirs(os.path.dirname(checkpoint_path) if os.path.dirname(checkpoint_path) else \".\", exist_ok=True)\n",
    "    \n",
    "    running = True\n",
    "    paused = False\n",
    "    current_fps = fps\n",
    "    \n",
    "    # Initialize pygame for rendering\n",
    "    if render:\n",
    "        pygame.init()\n",
    "        screen = pygame.display.set_mode((800, 600))\n",
    "        pygame.display.set_caption(f\"Q-Learning Phototaxis - FPS: {current_fps}\")\n",
    "        clock = pygame.time.Clock()\n",
    "        \n",
    "        # Font for displaying info\n",
    "        try:\n",
    "            font = pygame.font.Font(None, 24)\n",
    "            info_font = pygame.font.Font(None, 20)\n",
    "        except:\n",
    "            font = None\n",
    "            info_font = None\n",
    "    \n",
    "    try:\n",
    "        for ep_idx in trange(episode_count, desc=\"Training\", unit=\"ep\"):\n",
    "            actual_episode = start_episode + ep_idx\n",
    "            obs, _ = env.reset()\n",
    "            done = False\n",
    "            total_reward = {agentId: 0}\n",
    "            step_count = 0\n",
    "            \n",
    "            while not done and step_count < episode_max_steps:\n",
    "                # Handle pygame events\n",
    "                if render:\n",
    "                    for event in pygame.event.get():\n",
    "                        if event.type == pygame.QUIT:\n",
    "                            running = False\n",
    "                        elif event.type == pygame.KEYDOWN:\n",
    "                            if event.key == pygame.K_ESCAPE or event.key == pygame.K_q:\n",
    "                                running = False\n",
    "                            elif event.key == pygame.K_SPACE:\n",
    "                                paused = not paused\n",
    "                            elif event.key == pygame.K_UP:\n",
    "                                current_fps = min(240, current_fps + 10)\n",
    "                                pygame.display.set_caption(f\"Q-Learning Phototaxis - FPS: {current_fps}\")\n",
    "                            elif event.key == pygame.K_DOWN:\n",
    "                                current_fps = max(10, current_fps - 10)\n",
    "                                pygame.display.set_caption(f\"Q-Learning Phototaxis - FPS: {current_fps}\")\n",
    "                            elif event.key == pygame.K_s:\n",
    "                                # Manual save\n",
    "                                for agent_id, agent_obj in agents.items():\n",
    "                                    save_path = f\"{checkpoint_path}_manual_ep{actual_episode}\"\n",
    "                                    agent_obj.save(save_path)\n",
    "                                    print(f\"\\n[Manual Save] Episode {actual_episode}\")\n",
    "                \n",
    "                if not running:\n",
    "                    break\n",
    "                \n",
    "                # Skip step if paused\n",
    "                if paused and render:\n",
    "                    pygame.time.wait(100)\n",
    "                    continue\n",
    "                \n",
    "                # Choose and execute actions\n",
    "                actions = {\n",
    "                    k: agents[k].choose_action(v, epsilon_greedy=not render) \n",
    "                    for k, v in obs.items()\n",
    "                }\n",
    "                next_obs, rewards, terminateds, truncateds, _ = env.step(actions)\n",
    "                \n",
    "                done = terminateds[agentId] or truncateds[agentId]\n",
    "                \n",
    "                # Update Q-table (only during training)\n",
    "                if not render:\n",
    "                    for k in next_obs.keys():\n",
    "                        agents[k].update_q(obs[k], actions[k], rewards[k], next_obs[k], done)\n",
    "                        total_reward[k] += rewards[k]\n",
    "                else:\n",
    "                    # Track reward even during rendering\n",
    "                    total_reward[agentId] += rewards[agentId]\n",
    "                \n",
    "                obs = next_obs\n",
    "                \n",
    "                # Render visualization\n",
    "                if render:\n",
    "                    rgb_array = env.render()\n",
    "                    surface = pygame.surfarray.make_surface(np.transpose(rgb_array, (1, 0, 2)))\n",
    "                    screen.blit(surface, (0, 0))\n",
    "                    \n",
    "                    # Display info overlay\n",
    "                    if font and info_font:\n",
    "                        info_texts = [\n",
    "                            f\"Episode: {actual_episode + 1}/{start_episode + episode_count}\",\n",
    "                            f\"Step: {step_count}/{episode_max_steps}\",\n",
    "                            f\"Reward: {total_reward[agentId]:.2f}\",\n",
    "                            f\"Epsilon: {agents[agentId].epsilon:.4f}\",\n",
    "                            f\"FPS: {current_fps} (↑/↓ to adjust)\",\n",
    "                            f\"{'PAUSED' if paused else 'SPACE: Pause'}\"\n",
    "                        ]\n",
    "                        \n",
    "                        y_offset = 10\n",
    "                        for text in info_texts:\n",
    "                            color = (255, 255, 0) if paused else (255, 255, 255)\n",
    "                            text_surface = info_font.render(text, True, color, (0, 0, 0))\n",
    "                            screen.blit(text_surface, (10, y_offset))\n",
    "                            y_offset += 25\n",
    "                    \n",
    "                    pygame.display.flip()\n",
    "                    clock.tick(current_fps)\n",
    "                \n",
    "                step_count += 1\n",
    "            \n",
    "            if not running:\n",
    "                print(\"\\nTraining interrupted by user\")\n",
    "                break\n",
    "            \n",
    "            # Decay epsilon after episode\n",
    "            for agent_obj in agents.values():\n",
    "                agent_obj.decay_epsilon(actual_episode)\n",
    "            \n",
    "            # Save checkpoint at intervals\n",
    "            if checkpoint_interval and (ep_idx + 1) % checkpoint_interval == 0:\n",
    "                for agent_id, agent_obj in agents.items():\n",
    "                    save_path = f\"{checkpoint_path}_ep{actual_episode + 1}\"\n",
    "                    agent_obj.save(save_path)\n",
    "                    print(f\"\\n[Checkpoint] Saved at episode {actual_episode + 1}\")\n",
    "    \n",
    "    finally:\n",
    "        # Cleanup pygame\n",
    "        if render:\n",
    "            pygame.quit()\n",
    "        \n",
    "        # Final save if checkpointing was enabled\n",
    "        if checkpoint_interval and running:\n",
    "            for agent_id, agent_obj in agents.items():\n",
    "                save_path = f\"{checkpoint_path}_final\"\n",
    "                agent_obj.save(save_path)\n",
    "                print(f\"\\n[Final Save] Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Trained Agent\n",
    "\n",
    "**Keyboard Controls (during render):**\n",
    "- `↑/↓`: Adjust FPS (10-240)\n",
    "- `SPACE`: Pause/Resume\n",
    "- `S`: Manual checkpoint save\n",
    "- `ESC/Q`: Quit training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/feature/deepqlearning-obstacle-avoidance/python/src/scripts/checkpoints/oa_ep1000\n",
      "2025-10-30 11:08:49,979 — INFO — Agent loaded from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/feature/deepqlearning-obstacle-avoidance/python/src/scripts/checkpoints/oa_ep1000.npz\n",
      "2025-10-30 11:08:49,980 — INFO —   Q-table shape: (6561, 3)\n",
      "2025-10-30 11:08:49,980 — INFO —   Current epsilon: 0.0327\n",
      "2025-10-30 11:08:49,980 — INFO —   Total episodes trained: 1000\n",
      "Loaded agent from /home/simone/uni-lab/PPS/2024/SRS/PPS-22-srs/feature/deepqlearning-obstacle-avoidance/python/src/scripts/checkpoints/oa_ep1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                                                                                           | 0/1 [00:05<?, ?ep/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training interrupted by user\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with rendering (use ↑/↓ to adjust speed, SPACE to pause)\n",
    "path = get_yaml_path(\"src\", \"scripts\", \"checkpoints\", \"oa_ep1000\")\n",
    "run_episodes(1, 10000, render=True, load_checkpoint=path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
